Loading...

The system can't perform the operation now. Try again later.

[](javascript:void(0))

Cite
----

[](javascript:void(0))

Advanced search
---------------

**Find articles**

with **all** of the words

with the **exact phrase**

with **at least one** of the words

**without** the words

where my words occur

anywhere in the article

in the title of the article

Return articles **authored** by

e.g., _"PJ Hayes"_ or _McCarthy_

Return articles **published** in

e.g., _J Biol Chem_ or _Nature_

Return articles **dated** between

 — 

e.g., _1996_

[](javascript:void(0))

Saved to My library
-------------------

DoneRemove article

[](javascript:void(0))
[](/schhp?hl=en&as_sdt=0,5)

[Articles](/scholar?as_sdt=0,5&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en)
[Case law](/scholar?as_sdt=2006&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en)
[Profiles](/citations?view_op=search_authors&mauthors=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&oi=drw)

[My profile](/citations?hl=en)
[My library](/scholar?scilib=1&scioq=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
[Alerts](/scholar_alerts?view_op=list_alerts&hl=en)
[Metrics](/citations?view_op=metrics_intro&hl=en)

[Advanced search](javascript:void(0))

[Settings](/scholar_settings?q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)

[Sign in](https://accounts.google.com/Login?hl=en&continue=https://scholar.google.com/scholar%3Fas_q%3D%26num%3D10%26btnG%3DSearch%2BScholar%26as_epq%3DMisspecification%2Bin%2BInverse%2BReinforcement%2BLearning%26as_oq%3D%26as_eq%3D%26as_occt%3Dany%26as_sauthors%3DSkalse)

[](javascript:void(0))
[](/schhp?hl=en&as_sdt=0,5)

[Sign in](https://accounts.google.com/Login?hl=en&continue=https://scholar.google.com/scholar%3Fas_q%3D%26num%3D10%26btnG%3DSearch%2BScholar%26as_epq%3DMisspecification%2Bin%2BInverse%2BReinforcement%2BLearning%26as_oq%3D%26as_eq%3D%26as_occt%3Dany%26as_sauthors%3DSkalse)

[](javascript:void(0))

Articles

Scholar

[My profile](/citations?hl=en)
[My library](/scholar?scilib=1&scioq=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)

Year

[Any time](/scholar?q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
[Since 2024](/scholar?as_ylo=2024&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
[Since 2023](/scholar?as_ylo=2023&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
[Since 2020](/scholar?as_ylo=2020&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)

[Sort by relevance](/scholar?hl=en&as_sdt=0,5&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse)
[Sort by date](/scholar?hl=en&as_sdt=0,5&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&scisbd=1)

[Any type](/scholar?q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
[Review articles](/scholar?q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5&as_rr=1)

[include patents](/scholar?as_sdt=2007&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en)
[include citations](/scholar?as_vis=1&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)

*   [Any time](/scholar?q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
    
*   [Since 2024](/scholar?as_ylo=2024&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
    
*   [Since 2023](/scholar?as_ylo=2023&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
    
*   [Since 2020](/scholar?as_ylo=2020&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
    
*   [Custom range...](javascript:void(0))
    

—

Search

*   [Sort by relevance](/scholar?hl=en&as_sdt=0,5&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse)
    
*   [Sort by date](/scholar?hl=en&as_sdt=0,5&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&scisbd=1)
    

*   [Any type](/scholar?q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
    
*   [Review articles](/scholar?q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5&as_rr=1)
    

*   [include patents](/scholar?as_sdt=2007&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en)
    
*   [include citations](/scholar?as_vis=1&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
    

[\[PDF\] aaai.org](https://ojs.aaai.org/index.php/AAAI/article/view/26766/26538)

### [Misspecification in inverse reinforcement learning](https://ojs.aaai.org/index.php/AAAI/article/view/26766)

[J Skalse](/citations?user=GuzLUmQAAAAJ&hl=en&oi=sra)
, [A Abate](/citations?user=yskbfM4AAAAJ&hl=en&oi=sra)
 - Proceedings of the AAAI Conference on Artificial …, 2023 - ojs.aaai.org

[J Skalse](/citations?user=GuzLUmQAAAAJ&hl=en&oi=sra)
, [A Abate](/citations?user=yskbfM4AAAAJ&hl=en&oi=sra)

Proceedings of the AAAI Conference on Artificial Intelligence, 2023•ojs.aaai.org

Abstract The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function R from  
a policy pi. To do this, we need a model of how pi relates to R. In the current literature, the  
most common models are optimality, Boltzmann rationality, and causal entropy  
maximisation. One of the primary motivations behind IRL is to infer human preferences from  
human behaviour. However, the true relationship between human preferences and human  
behaviour is much more complex than any of the models currently used in IRL. This means …

Abstract

The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function R from a policy pi. To do this, we need a model of how pi relates to R. In the current literature, the most common models are optimality, Boltzmann rationality, and causal entropy maximisation. One of the primary motivations behind IRL is to infer human preferences from human behaviour. However, the true relationship between human preferences and human behaviour is much more complex than any of the models currently used in IRL. This means that they are misspecified, which raises the worry that they might lead to unsound inferences if applied to real-world data. In this paper, we provide a mathematical analysis of how robust different IRL models are to misspecification, and answer precisely how the demonstrator policy may differ from each of the standard models before that model leads to faulty inferences about the reward function R. We also introduce a framework for reasoning about misspecification in IRL, together with formal tools that can be used to easily derive the misspecification robustness of new IRL models.

ojs.aaai.org

[Show moreShow less](javascript:void(0))

[Save](javascript:void(0))
 [Cite](javascript:void(0))
 [Cited by 19](/scholar?cites=14162821081477132480&as_sdt=2005&sciodt=0,5&hl=en)
 [Related articles](/scholar?q=related:wLDbWrxyjMQJ:scholar.google.com/&scioq=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
 [All 5 versions](/scholar?cluster=14162821081477132480&hl=en&as_sdt=0,5)
 [](javascript:void(0) "More")
[View as HTML](https://scholar.googleusercontent.com/scholar?q=cache:wLDbWrxyjMQJ:scholar.google.com/+%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)
[](javascript:void(0) "Fewer")

Showing the best result for this search. [See all results](/scholar?lookup=0&q=%22Misspecification+in+Inverse+Reinforcement+Learning%22+author:Skalse&hl=en&as_sdt=0,5)

[Privacy](//www.google.com/intl/en/policies/privacy/)
[Terms](//www.google.com/intl/en/policies/terms/)
[Help](javascript:void(0))

[About Scholar](/intl/en/scholar/about.html)
[Search help](//support.google.com/websearch?p=scholar_dsa&hl=en)